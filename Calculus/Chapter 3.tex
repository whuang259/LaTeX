\section{Derivatives}
\subsection{Introduction to Derivatives}

There are three ideas at the core of calculus. We've already covered one so far, the limit, and you've all (mostly) survived so now we can move on to the derivative. Here's the problem: slopes of lines is easy, take any two points and use the slope formula. But if I point to some point on a quadratic and ask you to give me the slope then you're shit out of luck. Luckily with the power of god and \st{anime} limits on your side, we can rectify this issue (in just a few more pages too!).

To begin, what exactly does the slope at a single point mean. We can easily find the slope between two points by drawing a line between them, but for a curve there's no lines. For the case of a curve, the slope at a single point will be the slope of line which \emph{just barely} touches the curve at that point. In other words we want the slope of the tangent line of the curve at that point. But to find the slope of a tangent line, we must first discuss secant lines.

As opposed to tangent lines, we get a secant line by taking two points on a curve and drawing a line through them. For instance if we have the function $f(x) = x^2$ and we want the secant line through $x = 1$ and $x = 3$, then the slope is
\[ m = \frac{f(3) - f(1)}{3 - 1} = \frac{9 - 1}{2} = 4 \]
We can make this equation much more general:

\begin{definition}[Difference Quotient]
	Let $f$ be a function which is defined (i.e. exists) on some interval. Let $x$ be some point inside that interval and $h \neq 0$ a number such that $x + h$ is still in the interval. Then the difference quotient is
	\[ Q = \frac{f(x + h) - f(x)}{h} \]
\end{definition}

A geometrical interpretation of this equation is that it is the slope of the secant line through $x$ and the point $h$ away. If we want to get the slope of the tangent line, then we simply move that second point closer and closer to the first point. In other words, we take the limit as $h$ (the horizontal distance between the two points of the secant line) goes to 0.

In the figure below, we see graphically how we can get to a tangent line by first taking a secant line and then decreasing the distance between the two points until they converge to just one. This will give a visualization for the actual definition of a derivative which represents this idea using a limit.

\begin{center}
	\includegraphics[scale=0.55]{images/Figure 3.1.1.png}
\end{center}

\begin{definition}[Derivatives]
	Let $f$ be a function which is defined on some open interval and $a$ some number in that interval (open interval means that $a$ cannot be either endpoint). Then the derivative of $f$ at $a$, or the slope of the tangent line at $x = a$, is given by the limit
	\[ f'(a) = \lim_{h \to 0} \frac{f(a + h) - f(a)}{h} \] 
\end{definition}

\begin{example}
	Let's take perhaps the simplest example (asides from constants) known to man, a linear function
	\[ f(x) = x \]
	Then the derivative, the slope of the tangent line, at any point $x = a$ is
	\[ f'(a) = \lim_{h \to 0} \frac{(a + h) - a}{h} = \lim_{h \to 0} \frac{h}{h} = \lim_{h \to 0} 1 = 1 \]
	This makes sense because the tangent line to a line is the line itself and the slope of a line does not change.
\end{example}

\begin{example}
	Here's a more complicated example
	\[ f(x) = x^2 \]
	Again we'll be general and consider any point $x = a$.
	\begin{align*}
		f'(a) &= \lim_{h \to 0} \frac{(a + h)^2 - a^2}{h} = \lim_{h \to 0} \frac{a^2 + 2ah + h^2 - a^2}{h} \\
		&= \lim_{h \to 0} \frac{2ah + h^2}{h} = \lim_{h \to 0} 2a + h \\
		&= 2a
	\end{align*}
	So the slope of a tangent line at some $x$ value is two times that $x$ value.
\end{example}

\newpage 
\begin{example}
	One more example
	\[ f(x) = \sqrt{x} \]
	This limit is slightly more involved
	\begin{align*}
		f'(a) &= \lim_{h \to 0} \frac{\sqrt{a + h} - \sqrt{a}}{h} \\
		&= \lim_{h \to 0} \frac{a + h - a}{h (\sqrt{a + h} + \sqrt{a})} = \lim_{h \to 0} \frac{h}{h(\sqrt{a + h} + \sqrt{a})} \\
		&= \lim_{h \to 0} \frac{1}{\sqrt{a + h} + \sqrt{a}} = \frac{1}{\sqrt{a} + \sqrt{a}} \\
		&= \frac{1}{2 \sqrt{a}}
	\end{align*}
\end{example}

Sometimes you might hear a derivative referred to as an \emph{instantaneous rate of change}, this comes from physics where the slope of something represents its rate of change. With this in mind, let's do a couple more examples but set in the real world.

\begin{example}
	Suppose we chuck a ball into the air such that its height is given by
	\[ y(t) = -5t^2 + 10t \]
	We want to know exactly how fast the ball is falling when it hits the ground, so first we solve for the time when it does hit the ground.
	\[ y(t) = -5t(t - 2) = 0 \thus t = 0, 2 \]
	$t = 0$ is when we first yeet the ball, so $t = 2$ is when it comes back down. Now we can do the limit
	\begin{align*}
		v(2) = y'(2) &= \lim_{h \to 0} \frac{y(t + h) - y(t)}{h} \\
		&= \lim_{h \to 0} \frac{(-5(2 + h)^2 + 10(2 + h)) - (-5(2)^2 + 10(2))}{h} \\
		&= \lim_{h \to 0} \frac{-5(4 + 4h + h^2) + 20 + 10h - 0}{h} \\
		&= \lim_{h \to 0} \frac{-10h - 5h^2}{h} = \lim_{h \to 0} -10 - 5h \\
		&= -10
	\end{align*}
	For that have done some physics before may notice that I set up this problem such that we throw the ball up in the air with speed $\SI{10}{m/s}$ (and rounded the acceleration due to gravity to $\SI{10}{m/s^2}$). The fact that the ball hits the ground exactly as fast as we threw it up is a neat result and you can verify that this is the case for other initial velocities as well.
\end{example}

So far we've been evaluating the derivative at a specific point, but there is nothing really stopping us from defining a function which gives derivatives for an arbitrary input. This function, read ``f prime," is what we will refer to as the derivative from here on out.
\[ f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} \]

We will investigate exactly what the derivative means more later, but we can still gain a basic understanding right now. The derivative is a function which returns the slope of a tangent line at any point $x$. In a certain way, this is the ``slope" at that point, how fast the function is going up or down. So for now, we can think of the derivative as a function which tells use how fast a function is increase (or decreasing if $f'(x) < 0$). 

There is a crucial connection between derivative and continuity.
\begin{theorem}[Continuity and Differentiability]
	If a function $f(x)$ is differentiable (i.e. the derivative exists) at $x = a$, then it must be continuous at $x = a$.
\end{theorem}

This gives us a shortcut from the limits we introduced last chapter. If we can somehow compute a derivative (function) and that function is not undefined at some point, then we will know that function is also continuous there. Now the curious reader may ask "Well what about the other way around? Are continuous functions always differentiable? " The answer is no. 

\begin{center}
	\includegraphics[scale=1]{images/Figure 3.1.2.png} 
\end{center}

Once we take the derivative of a function, there is nothing stopping us from doing it again. For instance, using derivatives we found in previous examples we can take a double derivative (and more, which I will leave for you to verify)
\[ f(x) = x^2 \thus 2x \thus 2 \thus 0 \]

These are called ``higher-order" derivatives, but generally we will refer to them by the amount of derivatives taken. Going back to the example of $f(x) = x^2$; the first derivative is $2x$, the second derivative is $2$ and the third derivative is $0$. This pattern continues, for any function $f$, the $n$-th derivative will be the function resulting from taking the derivative $n$ times.

There is two (three if you're a physicist and four if you're a mathematician) ways to write a derivative. Suppose we have a function $f(x)$, then Lagrange notation\footnote{You do not need to know what this is called.} denotes the derivatives as
\[ f'(x) \qquad f''(x) \qquad f'''(x) \qquad f^{(4)}(x) \qquad \cdots \qquad f^{(n)}(x)\]
It is customary to use the dashes for the first three derivatives, but start writing the numbers for higher derivatives. The other common notation in calculus is Liebniz's notation
\[ \dv{f}{x} \qquad \dv[2]{f}{x} \qquad \dv[3]{f}{x} \qquad \dv[4]{f}{x} \qquad \cdots \qquad \dv[n]{f}{x} \]
The reason for the numbers being where they are comes from the following
\[ \dv{x} \qty( \dv{x} \qty( \dv{f}{x} )) = \dv{x} \qty( \dv[2]{f}{x} ) = \dv[3]{f}{x} \]
Though don't write $\dd^3x^3$ on the bottom, to make sense of this you should think of the entire $\dd x$ as its own block (add invisible parentheses if that makes you feel better).

Having to go through an entire limit to get a derivative is a bit tedious, especially as the functions we consider become more and more complicated. Just like how we can build arbitrary limits out of basic ones, there are rules that let us construct more advanced derivatives from basic ones. 

\begin{example}
	First we need to establish two basic results, one we did earlier and the other can be easily proven
	\[ \dv{x}(c) = 0 \qquad \dv{x}(x) = 1 \] 
\end{example}

\newpage 
Now we introduce perhaps the most useful derivative rule in calculus:

\begin{theorem}[The Power Rule]
	For any real number $n \neq 0$, the derivative of the function $f(x) = x^n$ is 
	\[ f'(x) = n x^{n - 1} \]
\end{theorem}

It is important to note that this holds for any nonzero exponent, negative numbers and fractions included.

\begin{example}
	Let's rapid fire run through a bunch of examples, some of which we did using the limit definition earlier and others you will have to take my word that the limit definition gives the same result.
	\[ \dv{x}(x^2) = 2x \qquad \dv{x}(x^3) = 3x^2 \qquad \dv{x}(\sqrt{x}) = \frac{1}{2}x^{-1/2} = \frac{1}{2\sqrt{x}} \]
	\[ \dv{x}(\frac{1}{x}) = \dv{x}(x^{-1}) = x^{-2} = \frac{1}{x^2} \qquad \dv{x}(x^{3/4}) = \frac{3}{4}x^{-1/4} = \frac{3}{4\sqrt[4]{x}} \]
\end{example}

Another simple but useful rule is the constant rule, essentially stating that you can pull out constant coefficients when computing a derivative.
\[ \dv{x}(cf(x)) = c \dv{x}(f(x)) = c f'(x) \]

The final piece of the puzzle is the sum rule, using this we can start taking derivatives of basically every polynomial function.

\begin{theorem}[Sum Rule]
	Let $f(x)$ and $g(x)$ be two differentiable functions, then
	\[ \dv{x}(f(x) + g(x)) = \dv{f}{x} + \dv{g}{x} = f'(x) + g'(x) \]
\end{theorem}

To see this in action, we will run through the derivative of a simple polynomial while elaborating every single step we take. In general we won't have to be this verbose, but it is helpful to do so at least once to see how these rules are used.

\begin{example}
	Consider the function $f(x) = 3x^2 + 2x + 4$, the derivative is
	\begin{align*}
		f'(x) &= (3x^2 + 2x + 4)' \\
		&= (3x^2)' + (2x)' + (4)' \\
		&= 3 (x^2)' + 2 (x)' + 4(1)' \\
		&= 3(2x) + 2(1) + 4(0) \\
		&= 6x + 2
	\end{align*}
\end{example}

The sum rule in conjunction with the constant rule means that we can take derivative of subtracted functions as well. The last two operations to complete our collection are multiplication and division.

\begin{theorem}[Product Rule]
	Let $f(x)$ and $g(x)$ be differentiable functions, then
	\[ \dv{x}(f(x)g(x)) = f'(x)g(x) + f(x)g'(x) \]
\end{theorem}

The becomes useful when we have factored polynomials.

\begin{example}
	Take the derivative of $f(x) = (x^2 + 3)(x^2 - 4x)$. One way is to expand
	\[ f(x) = x^4 -4x^3 + 3x^2 - 12x \thus f'(x) = 4x^3 - 12x + 6x - 12 \]
	This is not feasible when the factors get longer, instead we can use the product rule
	\[ f'(x) = (x^2 +3)'(x^2 - 4x) + (x^2 + 3)(x^2 - 4x)' = (2x)(x^2 - 4x) + (2x)(x^2 - 4x) \]
\end{example}

You may complain ``wait, we haven't expanded the final result, this doesn't actually stop any algebra from happening." However this answer is just as good because often we are concerned with a single point. Regardless of the form it's in, we can still plug in values to get derivatives at specific points.

\begin{theorem}[Quotient Rule]
	Let $f(x)$ and $g(x)$ be differentiable functions, then
	\[ \dv{x}(\frac{f(x)}{g(x)}) = \frac{f'(x)g(x) - f(x)g'(x)}{(g(x))^2} \]
\end{theorem}

If this seems a bit hard to remember, the standard trick is to repeat to yourself "low d high minus high d low over low squared" which means to take the bottom function times the derivative of the top function and then subtract the top function times the derivative of the bottom function, all divided by the bottom squared. Another way is to just write the product rule on top but with a minus sign.

\begin{example}
	For a simple example, consider the function
	\[ f(x) = \frac{x + 1}{x - 1} \]
	One way is to use product rule, but then we would have to derive $1/(x+1)$ which we cannot do with normal rules, so instead we have to use quotient rule.
	\[ f'(x) = \frac{(x + 1)'(x - 1) - (x + 1)(x - 1)'}{(x - 1)^2} = \frac{(x - 1) - (x + 1)}{(x - 1)^2} = -\frac{2}{(x - 1)^2}\]
\end{example}

Let's put everything we've learned together with a more complicated example

\begin{example}
	Consider the function
	\[ f(x) = \frac{(2x + 1)(3x^2 + 4x + 2)}{x^2 - 1} \]
	The derivative is (we'll skip some algebra because you are seasoned derivers now)
	\begin{align*}
		f'(x) &= \frac{(2(3x^2 + 4x + 2) + (2x + 1)(6x + 4))(x^2 - 1) - (2x + 1)(3x^2 + 4x + 2)(2x)}{(x^2 - 1)^2} \\
		&= \frac{(18x^2 + 22x + 8)(x^2 - 1) - (4x^2 + 2x)(3x^2 + 4x + 2)}{(x^2 - 1)^2} \\
		&= \frac{6x^4 - 26x^2 - 26x - 8}{(x^2 - 1)^2}
	\end{align*}
\end{example}

\newpage 
\subsection{Applications of Derivatives}
Just like how we can find limits visually from a graph, we can also guess how the derivative of a function looks like by investigating its graph. There isn't a concrete procedure, but the general idea is:
\begin{itemize}
	\item If the function is going up, the derivative is positive. Vice versa for going down
	\item A horizontal tangent means the derivative is zero
	\item If the rate at which is function is growing is also growing, then the derivative should slope upwards. Similar logic applies to the other four cases.
\end{itemize}

\begin{example}
	The function $f(x)$ and $f'(x)$ are shown below
	\begin{center}
		\includegraphics[scale=0.75]{images/Figure 3.2.1.png} 
	\end{center}
\end{example}

\begin{example}
	For the function $f(x) = x^2 - 3x$, where is there a horizontal derivative?
	
	To answer this question we set the derivative to zero
	\[ f'(x) = 2x - 3 = 0 \thus x = \frac{3}{2} \]
	In particular the point $(3/2, 9/4)$ is a horizontal tangent. Observant readers may notice that this is the vertex of the parabola. In fact, the vertex of a quadratic will always have zero derivative.
\end{example}

We know that the average rate of a change of a function is the quotient
\[ \frac{f(a + h) - f(a)}{h} \]
For small values of $h$, we can pretend the function is just a line and estimate
\[ f'(a) \approx \frac{f(a + h) - f(a)}{h} \thus f(a + h) \approx f(a) + h f'(a) \]
This technique, known as linear approximation, lets us estimate the function using a known value and its derivative. 

\begin{example}
	Suppose we have a function $f(x)$ such that
	\[ f(5) = 10 \qquad f'(5) = 2 \]
	We can estimate the function at 6 using a linear approximation
	\[ f(7) \approx f(5) + 2f'(5) = 14 \]
\end{example}

If this seems a bit abstract, here's something more concrete.

\begin{example}
	We can use this approximation to estimate square roots. We know that 
	\[ f(x) = \sqrt{x} \thus f'(x) = \frac{1}{2\sqrt{x}} \]
	We also know that $\sqrt{4} = 2$, so we can estimate
	\begin{align*}
		\sqrt{5} &\approx 2 + \frac{1}{2\sqrt{4}} =  2.25 \text{ vs } 2.24\\
		\sqrt{6} &\approx 2 + 2 \cdot \frac{1}{2\sqrt{4}} =  2.5 \text{ vs } 2.45 \\
		\sqrt{7} &\approx 2 + 3 \cdot \frac{1}{2\sqrt{4}} =  2.75 \text{ vs } 2.65 \\
		\sqrt{8} &\approx 2 + 4 \cdot \frac{1}{2\sqrt{4}} =  3 \\
	\end{align*}
	Note that the approximate gets worse the further we are away from our reference point. 
\end{example}

A linear approximation is an example of a first order Taylor series, we can use the higher order derivatives to refine our approximation in a (much) later chapter.

Newton invented Calculus to provide a rigorous mathematical backing for his laws of motion. We will explore a bit of that here. 

\begin{definition}[Equations of Motion]
	Suppose the motion (position) of a particle over time is given by the function $x(t)$. Then the velocity of that particle is
	\[ v(t) = x'(t) \]
	The absolute value of velocity (i.e. its magnitude) is the particle's speed. The derivative of velocity gives its acceleration
	\[ a(t) = v'(t) = x''(t) \]
	The derivative of acceleration, the third derivative of position, is its jerk
	\[ j(t) = a'(t) = x''(t) = x'''(t) \]
	The next few higher order derivatives of position are snap, crack, and pop. You do not need to know the derivatives of position past acceleration.
\end{definition}

\begin{example}
	Consider a particle which moves according to
	\[ x(t) = t^3 - t^2 + 25 \]
	It's velocity and acceleration at a particular time is 
	\[ v(t) = 3t^2 - 2t \qquad a(t) = 6t - 2 \]
	From this we see that it is speeding up for $t > 1/3$ and slowing down otherwise. We can also solve
	\[ v(t) = t(3t - 2) > 0 \thus t < 0, t > 2/3 \]
	So for $t > 2/3$, the particle is moving forward.
\end{example}

In biology, particularly ecology, derivatives play a key role in modeling population dynamics. For instance, if the population of a city triples every 5 years and there are 10,000 people in the current year. Then
\[ P'(0) \approx \frac{P(5) - P(0)}{5 - 0} = \frac{30000 - 10000}{5} = 4000 \]
If we want to estimate the population in 3 years, then
\[ P(3) \approx P(0) + 3P'(0) = 10000 + 3 \cdot 4000 = 22000 \]

Population dynamics is more accurately modeled using the exponential function and differential equations, we will return to this example later when you learn what these are.

Derivatives are also used in economics when discuss the behavior of firms or other agents. In certain instances, we can use them to give optimal answers to questions like "How much should I produce of a certain good?" or "How much should I charge for this service?" 

\begin{example}
	In a monopolistically competitive market, the demand curve faced by a firm is equal to population demand due to market power. If the firm wishes to sell $x$ quantity of some good, then the price is given by
	\[ p(x) = 100 - x \]
	In other words, the firm can charge $50$ and sell 50 units or charge $99$ and only sell 1. The revenue is simply price times quantity and the derivative gives what is known as the marginal revenue: the additional revenue gained from selling one more unit.
	\[ R(x) = x p(x) = 100 x - x^2 \thus MR(x) = R'(x) = 100 - 2x \]
	Revenue is maximized when $MR = 0$ (you will learn why later), which occurs at exactly 50 goods sold. However this does not actually maximize profits.
	
	The cost to produce $x$ units of a good will be impacted by economies of scale. Just like revenue, we can differentiate to get the marginal cost: the cost to produce one more unit
	\[ C(x) = 16 + x^2 \thus MC(x) = C'(x) = 2x \]
	Profit in a monopolistic market is achieved when marginal cost equals marginal revenue
	\[ 100 - 2x = 2x \thus x = 25 \]
	and we see that the optimal quantity in this market is 25 units.
\end{example}

\newpage
\subsection{The Chain Rule}
The only thing stopping us from taking derivatives of any function we encounter is the fact that we don't know how to differentiate compositions of functions. The rule to do so is known as the Chain Rule.

\begin{theorem}[Chain Rule]
	Let $h(x) = (f \circ g)(x) = f(g(x))$, then the derivative is 
	\[ h'(x) = f'(g(x)) g'(x) \]
	In Leibniz notation, this is
	\[ \dv{h}{x} = \dv{h}{g} \cdot \dv{g}{x} \]
\end{theorem}

\begin{example}
	Consider the function
	\[ h(x) = (x^2 + 1)^2 \]
	This is a simple application of chain rule, the two functions are
	\[ f(x) = x^2 \qquad g(x) = x^2 + 1 \]
	and so the derivative is 
	\[ h'(x) = 2(x^2 + 1)(2x) = 4x(x^2 + 1) \]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \sin(x^3) \]
	It's pretty obvious what the outer and inner functions are
	\[ h'(x) = \cos(x^3)(3x^2) = 3x^2 \cos(x^3) \]
	
	Now suppose we want the tangent line at $x_0 = \sqrt[3]{\pi}$. First note
	\[ h(x_0) = \sin(\pi) = 0 \qquad h'(x_0) = 3\sqrt[3]{\pi^2}\cos(\pi) = -3\sqrt[3]{\pi^2} \]
	Using point-slope form, the tangent line is
	\[ y - 0 = -3\sqrt[3]{\pi^2}(x - \sqrt[3]{\pi}) \]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \frac{1}{x^3 + 5} \]
	For fractions, it's easy to miss that this is actually a composition of two functions
	\[ f(x) = \frac{1}{x} = \inv x \qquad g(x) = x^3 + 5 \]
	and so the derivative is
	\[ h'(x) = -(x^3 + 5)^{-2}(3x^2) = -\frac{3x^2}{(x^3 + 5)^2}\]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \cos(\cos(x^3)) \]
	This is an example of a nested chain rule, first we decompose
	\[ f(x) = \cos x \qquad g(x) = \cos(x^3) \]
	But now we have an issue, $g(x)$ is also a composition of functions
	\[ g(x) = \alpha(\beta(x)) \qquad \alpha(x) = \cos x \qquad \beta(x) = x^3 \]
	
	Starting from the top, recall that the chain rule state
	\[ h'(x) = f'(g(x)) g'(x) \]
	we can easily compute $f'(x)$, but we will need to use chain rule again to compute $g'(x)$
	\[ g'(x) = \alpha'(\beta(x)) \beta'(x) = -\sin(x^3) (3x^2) = -3x^2 \sin(x^3) \]
	
	Putting the pieces together, we get
	\[ h'(x) = -\sin( \cos(x^3)) (-3x^2 \sin(x^3)) = 3x^2 \sin(x^3) \sin(\cos(x^3)) \]
\end{example}

\newpage 
\subsection{Derivatives of Special Functions}
In this section we give the derivatives of functions not covered by the power rule, for instance trigonometric functions and exponential functions. We will start with the trig functions.

We compute the derivative of sine directly from the limit definition using sum to product identities
\begin{align*}
	\dv{x} (\sin x) &= \lim_{h \to 0} \frac{\sin(x + h) - \sin(x)}{h} \\
	&= \lim_{h \to 0} \frac{2\sin(h/2)\cos(x + h/2)}{h} \\
	&= \lim_{h \to 0} \frac{\sin(h/2)}{h/2} \cdot \lim_{h \to 0} \cos(x + h/2) \\
	&= 1 \cdot \lim_{h \to 0} \cos(x + h/2) \\
	&= \cos(x) \\
	\dv{x} (\cos x) &= \lim_{h \to 0} \frac{\cos(x + h) - \cos(x)}{h} \\
	&= \lim_{h \to 0} \frac{-2\sin(h/2)\sin(x + h/2)}{h} \\
	&= \lim_{h \to 0} \frac{\sin(h/2)}{h/2} \cdot \lim_{h \to 0} -\sin(x + h/2) \\
	&= 1 \cdot \lim_{h \to 0} -\sin(x + h/2) \\
	&= -\sin(x) 
\end{align*}

The derivative of tangent comes from quotient rule
\begin{align*}
	\dv{x} (\tan x) &= \dv{x} \qty(\frac{\sin x}{\cos x}) \\
	&= \frac{(\cos x)(\cos x) - (\sin x)(-\sin x)}{\cos^2 x} \\
	&= \frac{\cos^2 x + \sin^2 x}{\cos^2 x} \\
	&= \frac{1}{\cos^2 x} = \sec^2 x 
\end{align*}

Now that we can take derivatives of trig functions, we have a more useful use case of the product rule.
\begin{example}
	Consider the function
	\[ f(x) = x^2 \sin x \]
	This product cannot simply be expanded, we are forced to use product rule
	\[ f'(x) = 2x \sin x + x^2 \cos x \]
\end{example}

Using quotient rule, we can take derivatives of the remaining trig functions. I'll list them here for your convenience:
\begin{proposition}[Trig Derivatives]
	\begin{align*}
		\dv{x} (\sin x) &= \cos x \\
		\dv{x} (\cos x) &= -\sin x \\
		\dv{x} (\tan x) &= \frac{1}{\cos^2 x} = \sec^2 x \\
		\dv{x} (\csc x) &= - \frac{\cos x}{\sin^2 x} = -\csc x \cot x \\
		\dv{x} (\sec x) &= \frac{\sin x}{\cos^2 x} = \sec x \tan x \\
		\dv{x} (\cot x) &= -\frac{1}{\sin^2 x} = -\csc^2 x \\
	\end{align*}
\end{proposition}

Note that because sine and cosine are related by derivatives, we have the chain
\[ \sin x \thus \cos x \thus -\sin x \thus -\cos x \thus \sin x \thus \cdots \]
This is our first example of a function which is both infinitely differentiable and has nontrivial higher order derivatives. Compare this to polynomials, which always end up going to 0 if you take enough derivatives.

\begin{example}
	Suppose we want to know the equation of the tangent line of the function
	\[ f(x) = \sin x \cos x \]
	at the point $x = \pi$. First note that the derivative is
	\[ f'(x) = (\cos x)(\cos x) + (\sin x)(-\sin x) = \cos^2 x - \sin^2 x = \cos(2x) \]
	Recall that the derivative gives us the slope of the tangent line, it is $f'(\pi) = 1$. Now all we need is a point. The tangent line touches the function at only one point, that point must be the value of the function at $x = \pi$, which is $f(\pi) = 0$. The easiest way to find the equation is to use point slope form and convert if necessary
	\[ y - 0 = 1 \cdot (x - \pi) \thus y = x - \pi \]
\end{example}

\begin{example}
	A particle undergoing simple harmonic motion (for instance a mass on an ideal spring) has equation
	\[ x(t) = 5 \cos(t) \]
	We can use this to find the velocity at any time $t$
	\[ v(t) = x'(t) = -5 \sin(t) \]
	The velocity function is also periodic, by looking more closely we see that 
	\[ v(t) = 0 \iff t = 0, \pi, 2\pi, 3\pi, \cdots \]
	This is also when the spring is furthest away from the center (at $\pm 5$). The mass actually has zero speed when it reaches it's furthest point and this happens infinitely many times.
\end{example}

\newpage 
\subsection{It's About the \emph{Implication}}
\subsection{Hard Topic: Derivatives for the Morbidly Curious}