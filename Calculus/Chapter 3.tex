\section{Derivatives}
\subsection{Introduction to Derivatives}

There are three ideas at the core of calculus. We've already covered one so far, the limit, and you've all (mostly) survived so now we can move on to the derivative. Here's the problem: slopes of lines is easy, take any two points and use the slope formula. But if I point to some point on a quadratic and ask you to give me the slope then you're shit out of luck. Luckily with the power of god and \st{anime} limits on your side, we can rectify this issue (in just a few more pages too!).

To begin, what exactly does the slope at a single point mean. We can easily find the slope between two points by drawing a line between them, but for a curve there's no lines. For the case of a curve, the slope at a single point will be the slope of line which \emph{just barely} touches the curve at that point. In other words we want the slope of the tangent line of the curve at that point. But to find the slope of a tangent line, we must first discuss secant lines.

As opposed to tangent lines, we get a secant line by taking two points on a curve and drawing a line through them. For instance if we have the function $f(x) = x^2$ and we want the secant line through $x = 1$ and $x = 3$, then the slope is
\[ m = \frac{f(3) - f(1)}{3 - 1} = \frac{9 - 1}{2} = 4 \]
We can make this equation much more general:

\begin{definition}[Difference Quotient]
	Let $f$ be a function which is defined (i.e. exists) on some interval. Let $x$ be some point inside that interval and $h \neq 0$ a number such that $x + h$ is still in the interval. Then the difference quotient is
	\[ Q = \frac{f(x + h) - f(x)}{h} \]
\end{definition}

A geometrical interpretation of this equation is that it is the slope of the secant line through $x$ and the point $h$ away. If we want to get the slope of the tangent line, then we simply move that second point closer and closer to the first point. In other words, we take the limit as $h$ (the horizontal distance between the two points of the secant line) goes to 0.

In the figure below, we see graphically how we can get to a tangent line by first taking a secant line and then decreasing the distance between the two points until they converge to just one. This will give a visualization for the actual definition of a derivative which represents this idea using a limit.

\begin{center}
	\includegraphics[scale=0.55]{images/Figure 3.1.1.png}
\end{center}

\begin{definition}[Derivatives]
	Let $f$ be a function which is defined on some open interval and $a$ some number in that interval (open interval means that $a$ cannot be either endpoint). Then the derivative of $f$ at $a$, or the slope of the tangent line at $x = a$, is given by the limit
	\[ f'(a) = \lim_{h \to 0} \frac{f(a + h) - f(a)}{h} \] 
\end{definition}

\begin{example}
	Let's take perhaps the simplest example (asides from constants) known to man, a linear function
	\[ f(x) = x \]
	Then the derivative, the slope of the tangent line, at any point $x = a$ is
	\[ f'(a) = \lim_{h \to 0} \frac{(a + h) - a}{h} = \lim_{h \to 0} \frac{h}{h} = \lim_{h \to 0} 1 = 1 \]
	This makes sense because the tangent line to a line is the line itself and the slope of a line does not change.
\end{example}

\begin{example}
	Here's a more complicated example
	\[ f(x) = x^2 \]
	Again we'll be general and consider any point $x = a$.
	\begin{align*}
		f'(a) &= \lim_{h \to 0} \frac{(a + h)^2 - a^2}{h} = \lim_{h \to 0} \frac{a^2 + 2ah + h^2 - a^2}{h} \\
		&= \lim_{h \to 0} \frac{2ah + h^2}{h} = \lim_{h \to 0} 2a + h \\
		&= 2a
	\end{align*}
	So the slope of a tangent line at some $x$ value is two times that $x$ value.
\end{example}

\newpage 
\begin{example}
	One more example
	\[ f(x) = \sqrt{x} \]
	This limit is slightly more involved
	\begin{align*}
		f'(a) &= \lim_{h \to 0} \frac{\sqrt{a + h} - \sqrt{a}}{h} \\
		&= \lim_{h \to 0} \frac{a + h - a}{h (\sqrt{a + h} + \sqrt{a})} = \lim_{h \to 0} \frac{h}{h(\sqrt{a + h} + \sqrt{a})} \\
		&= \lim_{h \to 0} \frac{1}{\sqrt{a + h} + \sqrt{a}} = \frac{1}{\sqrt{a} + \sqrt{a}} \\
		&= \frac{1}{2 \sqrt{a}}
	\end{align*}
\end{example}

Sometimes you might hear a derivative referred to as an \emph{instantaneous rate of change}, this comes from physics where the slope of something represents its rate of change. With this in mind, let's do a couple more examples but set in the real world.

\begin{example}
	Suppose we chuck a ball into the air such that its height is given by
	\[ y(t) = -5t^2 + 10t \]
	We want to know exactly how fast the ball is falling when it hits the ground, so first we solve for the time when it does hit the ground.
	\[ y(t) = -5t(t - 2) = 0 \thus t = 0, 2 \]
	$t = 0$ is when we first yeet the ball, so $t = 2$ is when it comes back down. Now we can do the limit
	\begin{align*}
		v(2) = y'(2) &= \lim_{h \to 0} \frac{y(t + h) - y(t)}{h} \\
		&= \lim_{h \to 0} \frac{(-5(2 + h)^2 + 10(2 + h)) - (-5(2)^2 + 10(2))}{h} \\
		&= \lim_{h \to 0} \frac{-5(4 + 4h + h^2) + 20 + 10h - 0}{h} \\
		&= \lim_{h \to 0} \frac{-10h - 5h^2}{h} = \lim_{h \to 0} -10 - 5h \\
		&= -10
	\end{align*}
	For that have done some physics before may notice that I set up this problem such that we throw the ball up in the air with speed $\SI{10}{m/s}$ (and rounded the acceleration due to gravity to $\SI{10}{m/s^2}$). The fact that the ball hits the ground exactly as fast as we threw it up is a neat result and you can verify that this is the case for other initial velocities as well.
\end{example}

So far we've been evaluating the derivative at a specific point, but there is nothing really stopping us from defining a function which gives derivatives for an arbitrary input. This function, read ``f prime," is what we will refer to as the derivative from here on out.
\[ f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} \]

We will investigate exactly what the derivative means more later, but we can still gain a basic understanding right now. The derivative is a function which returns the slope of a tangent line at any point $x$. In a certain way, this is the ``slope" at that point, how fast the function is going up or down. So for now, we can think of the derivative as a function which tells use how fast a function is increase (or decreasing if $f'(x) < 0$). 

There is a crucial connection between derivative and continuity.
\begin{theorem}[Continuity and Differentiability]
	If a function $f(x)$ is differentiable (i.e. the derivative exists) at $x = a$, then it must be continuous at $x = a$.
\end{theorem}

This gives us a shortcut from the limits we introduced last chapter. If we can somehow compute a derivative (function) and that function is not undefined at some point, then we will know that function is also continuous there. Now the curious reader may ask "Well what about the other way around? Are continuous functions always differentiable? " The answer is no. 

\begin{center}
	\includegraphics[scale=1]{images/Figure 3.1.2.png} 
\end{center}

Once we take the derivative of a function, there is nothing stopping us from doing it again. For instance, using derivatives we found in previous examples we can take a double derivative (and more, which I will leave for you to verify)
\[ f(x) = x^2 \thus 2x \thus 2 \thus 0 \]

These are called ``higher-order" derivatives, but generally we will refer to them by the amount of derivatives taken. Going back to the example of $f(x) = x^2$; the first derivative is $2x$, the second derivative is $2$ and the third derivative is $0$. This pattern continues, for any function $f$, the $n$-th derivative will be the function resulting from taking the derivative $n$ times.

There is two (three if you're a physicist and four if you're a mathematician) ways to write a derivative. Suppose we have a function $f(x)$, then Lagrange notation\footnote{You do not need to know what this is called.} denotes the derivatives as
\[ f'(x) \qquad f''(x) \qquad f'''(x) \qquad f^{(4)}(x) \qquad \cdots \qquad f^{(n)}(x)\]
It is customary to use the dashes for the first three derivatives, but start writing the numbers for higher derivatives. The other common notation in calculus is Liebniz's notation
\[ \dv{f}{x} \qquad \dv[2]{f}{x} \qquad \dv[3]{f}{x} \qquad \dv[4]{f}{x} \qquad \cdots \qquad \dv[n]{f}{x} \]
The reason for the numbers being where they are comes from the following
\[ \dv{x} \qty( \dv{x} \qty( \dv{f}{x} )) = \dv{x} \qty( \dv[2]{f}{x} ) = \dv[3]{f}{x} \]
Though don't write $\dd^3x^3$ on the bottom, to make sense of this you should think of the entire $\dd x$ as its own block (add invisible parentheses if that makes you feel better).

Having to go through an entire limit to get a derivative is a bit tedious, especially as the functions we consider become more and more complicated. Just like how we can build arbitrary limits out of basic ones, there are rules that let us construct more advanced derivatives from basic ones. 

\begin{example}
	First we need to establish two basic results, one we did earlier and the other can be easily proven
	\[ \dv{x}(c) = 0 \qquad \dv{x}(x) = 1 \] 
\end{example}

\newpage 
Now we introduce perhaps the most useful derivative rule in calculus:

\begin{theorem}[The Power Rule]
	For any real number $n \neq 0$, the derivative of the function $f(x) = x^n$ is 
	\[ f'(x) = n x^{n - 1} \]
\end{theorem}

It is important to note that this holds for any nonzero exponent, negative numbers and fractions included.

\begin{example}
	Let's rapid fire run through a bunch of examples, some of which we did using the limit definition earlier and others you will have to take my word that the limit definition gives the same result.
	\[ \dv{x}(x^2) = 2x \qquad \dv{x}(x^3) = 3x^2 \qquad \dv{x}(\sqrt{x}) = \frac{1}{2}x^{-1/2} = \frac{1}{2\sqrt{x}} \]
	\[ \dv{x}(\frac{1}{x}) = \dv{x}(x^{-1}) = x^{-2} = \frac{1}{x^2} \qquad \dv{x}(x^{3/4}) = \frac{3}{4}x^{-1/4} = \frac{3}{4\sqrt[4]{x}} \]
\end{example}

Another simple but useful rule is the constant rule, essentially stating that you can pull out constant coefficients when computing a derivative.
\[ \dv{x}(cf(x)) = c \dv{x}(f(x)) = c f'(x) \]

The final piece of the puzzle is the sum rule, using this we can start taking derivatives of basically every polynomial function.

\begin{theorem}[Sum Rule]
	Let $f(x)$ and $g(x)$ be two differentiable functions, then
	\[ \dv{x}(f(x) + g(x)) = \dv{f}{x} + \dv{g}{x} = f'(x) + g'(x) \]
\end{theorem}

To see this in action, we will run through the derivative of a simple polynomial while elaborating every single step we take. In general we won't have to be this verbose, but it is helpful to do so at least once to see how these rules are used.

\begin{example}
	Consider the function $f(x) = 3x^2 + 2x + 4$, the derivative is
	\begin{align*}
		f'(x) &= (3x^2 + 2x + 4)' \\
		&= (3x^2)' + (2x)' + (4)' \\
		&= 3 (x^2)' + 2 (x)' + 4(1)' \\
		&= 3(2x) + 2(1) + 4(0) \\
		&= 6x + 2
	\end{align*}
\end{example}

The sum rule in conjunction with the constant rule means that we can take derivative of subtracted functions as well. The last two operations to complete our collection are multiplication and division.

\begin{theorem}[Product Rule]
	Let $f(x)$ and $g(x)$ be differentiable functions, then
	\[ \dv{x}(f(x)g(x)) = f'(x)g(x) + f(x)g'(x) \]
\end{theorem}

The becomes useful when we have factored polynomials.

\begin{example}
	Take the derivative of $f(x) = (x^2 + 3)(x^2 - 4x)$. One way is to expand
	\[ f(x) = x^4 -4x^3 + 3x^2 - 12x \thus f'(x) = 4x^3 - 12x + 6x - 12 \]
	This is not feasible when the factors get longer, instead we can use the product rule
	\[ f'(x) = (x^2 +3)'(x^2 - 4x) + (x^2 + 3)(x^2 - 4x)' = (2x)(x^2 - 4x) + (2x)(x^2 - 4x) \]
\end{example}

You may complain ``wait, we haven't expanded the final result, this doesn't actually stop any algebra from happening." However this answer is just as good because often we are concerned with a single point. Regardless of the form it's in, we can still plug in values to get derivatives at specific points.

\begin{theorem}[Quotient Rule]
	Let $f(x)$ and $g(x)$ be differentiable functions, then
	\[ \dv{x}(\frac{f(x)}{g(x)}) = \frac{f'(x)g(x) - f(x)g'(x)}{(g(x))^2} \]
\end{theorem}

If this seems a bit hard to remember, the standard trick is to repeat to yourself "low d high minus high d low over low squared" which means to take the bottom function times the derivative of the top function and then subtract the top function times the derivative of the bottom function, all divided by the bottom squared. Another way is to just write the product rule on top but with a minus sign.

\begin{example}
	For a simple example, consider the function
	\[ f(x) = \frac{x + 1}{x - 1} \]
	One way is to use product rule, but then we would have to derive $1/(x+1)$ which we cannot do with normal rules, so instead we have to use quotient rule.
	\[ f'(x) = \frac{(x + 1)'(x - 1) - (x + 1)(x - 1)'}{(x - 1)^2} = \frac{(x - 1) - (x + 1)}{(x - 1)^2} = -\frac{2}{(x - 1)^2}\]
\end{example}

Let's put everything we've learned together with a more complicated example

\begin{example}
	Consider the function
	\[ f(x) = \frac{(2x + 1)(3x^2 + 4x + 2)}{x^2 - 1} \]
	The derivative is (we'll skip some algebra because you are seasoned derivers now)
	\begin{align*}
		f'(x) &= \frac{(2(3x^2 + 4x + 2) + (2x + 1)(6x + 4))(x^2 - 1) - (2x + 1)(3x^2 + 4x + 2)(2x)}{(x^2 - 1)^2} \\
		&= \frac{(18x^2 + 22x + 8)(x^2 - 1) - (4x^2 + 2x)(3x^2 + 4x + 2)}{(x^2 - 1)^2} \\
		&= \frac{6x^4 - 26x^2 - 26x - 8}{(x^2 - 1)^2}
	\end{align*}
\end{example}

\newpage 
\subsection{Applications of Derivatives}
Just like how we can find limits visually from a graph, we can also guess how the derivative of a function looks like by investigating its graph. There isn't a concrete procedure, but the general idea is:
\begin{itemize}
	\item If the function is going up, the derivative is positive. Vice versa for going down
	\item A horizontal tangent means the derivative is zero
	\item If the rate at which is function is growing is also growing, then the derivative should slope upwards. Similar logic applies to the other four cases.
\end{itemize}

\begin{example}
	The function $f(x)$ and $f'(x)$ are shown below
	\begin{center}
		\includegraphics[scale=0.75]{images/Figure 3.2.1.png} 
	\end{center}
\end{example}

\begin{example}
	For the function $f(x) = x^2 - 3x$, where is there a horizontal derivative?
	
	To answer this question we set the derivative to zero
	\[ f'(x) = 2x - 3 = 0 \thus x = \frac{3}{2} \]
	In particular the point $(3/2, 9/4)$ is a horizontal tangent. Observant readers may notice that this is the vertex of the parabola. In fact, the vertex of a quadratic will always have zero derivative.
\end{example}

We know that the average rate of a change of a function is the quotient
\[ \frac{f(a + h) - f(a)}{h} \]
For small values of $h$, we can pretend the function is just a line and estimate
\[ f'(a) \approx \frac{f(a + h) - f(a)}{h} \thus f(a + h) \approx f(a) + h f'(a) \]
This technique, known as linear approximation, lets us estimate the function using a known value and its derivative. 

\begin{example}
	Suppose we have a function $f(x)$ such that
	\[ f(5) = 10 \qquad f'(5) = 2 \]
	We can estimate the function at 6 using a linear approximation
	\[ f(7) \approx f(5) + 2f'(5) = 14 \]
\end{example}

If this seems a bit abstract, here's something more concrete.

\begin{example}
	We can use this approximation to estimate square roots. We know that 
	\[ f(x) = \sqrt{x} \thus f'(x) = \frac{1}{2\sqrt{x}} \]
	We also know that $\sqrt{4} = 2$, so we can estimate
	\begin{align*}
		\sqrt{5} &\approx 2 + \frac{1}{2\sqrt{4}} =  2.25 \text{ vs } 2.24\\
		\sqrt{6} &\approx 2 + 2 \cdot \frac{1}{2\sqrt{4}} =  2.5 \text{ vs } 2.45 \\
		\sqrt{7} &\approx 2 + 3 \cdot \frac{1}{2\sqrt{4}} =  2.75 \text{ vs } 2.65 \\
		\sqrt{8} &\approx 2 + 4 \cdot \frac{1}{2\sqrt{4}} =  3 \\
	\end{align*}
	Note that the approximate gets worse the further we are away from our reference point. 
\end{example}

A linear approximation is an example of a first order Taylor series, we can use the higher order derivatives to refine our approximation in a (much) later chapter.

Newton invented Calculus to provide a rigorous mathematical backing for his laws of motion. We will explore a bit of that here. 

\begin{definition}[Equations of Motion]
	Suppose the motion (position) of a particle over time is given by the function $x(t)$. Then the velocity of that particle is
	\[ v(t) = x'(t) \]
	The absolute value of velocity (i.e. its magnitude) is the particle's speed. The derivative of velocity gives its acceleration
	\[ a(t) = v'(t) = x''(t) \]
	The derivative of acceleration, the third derivative of position, is its jerk
	\[ j(t) = a'(t) = x''(t) = x'''(t) \]
	The next few higher order derivatives of position are snap, crack, and pop. You do not need to know the derivatives of position past acceleration.
\end{definition}

\begin{example}
	Consider a particle which moves according to
	\[ x(t) = t^3 - t^2 + 25 \]
	It's velocity and acceleration at a particular time is 
	\[ v(t) = 3t^2 - 2t \qquad a(t) = 6t - 2 \]
	From this we see that it is speeding up for $t > 1/3$ and slowing down otherwise. We can also solve
	\[ v(t) = t(3t - 2) > 0 \thus t < 0, t > 2/3 \]
	So for $t > 2/3$, the particle is moving forward.
\end{example}

In biology, particularly ecology, derivatives play a key role in modeling population dynamics. For instance, if the population of a city triples every 5 years and there are 10,000 people in the current year. Then
\[ P'(0) \approx \frac{P(5) - P(0)}{5 - 0} = \frac{30000 - 10000}{5} = 4000 \]
If we want to estimate the population in 3 years, then
\[ P(3) \approx P(0) + 3P'(0) = 10000 + 3 \cdot 4000 = 22000 \]

Population dynamics is more accurately modeled using the exponential function and differential equations, we will return to this example later when you learn what these are.

Derivatives are also used in economics when discuss the behavior of firms or other agents. In certain instances, we can use them to give optimal answers to questions like "How much should I produce of a certain good?" or "How much should I charge for this service?" 

\begin{example}
	In a monopolistically competitive market, the demand curve faced by a firm is equal to population demand due to market power. If the firm wishes to sell $x$ quantity of some good, then the price is given by
	\[ p(x) = 100 - x \]
	In other words, the firm can charge $50$ and sell 50 units or charge $99$ and only sell 1. The revenue is simply price times quantity and the derivative gives what is known as the marginal revenue: the additional revenue gained from selling one more unit.
	\[ R(x) = x p(x) = 100 x - x^2 \thus MR(x) = R'(x) = 100 - 2x \]
	Revenue is maximized when $MR = 0$ (you will learn why later), which occurs at exactly 50 goods sold. However this does not actually maximize profits.
	
	The cost to produce $x$ units of a good will be impacted by economies of scale. Just like revenue, we can differentiate to get the marginal cost: the cost to produce one more unit
	\[ C(x) = 16 + x^2 \thus MC(x) = C'(x) = 2x \]
	Profit in a monopolistic market is achieved when marginal cost equals marginal revenue
	\[ 100 - 2x = 2x \thus x = 25 \]
	and we see that the optimal quantity in this market is 25 units.
\end{example}

\newpage
\subsection{The Chain and Inverse Rules}
The only thing stopping us from taking derivatives of any function we encounter is the fact that we don't know how to differentiate compositions of functions. The rule to do so is known as the Chain Rule.

\begin{theorem}[Chain Rule]
	Let $h(x) = (f \circ g)(x) = f(g(x))$, then the derivative is 
	\[ h'(x) = f'(g(x)) g'(x) \]
	In Leibniz notation, this is
	\[ \dv{h}{x} = \dv{h}{g} \cdot \dv{g}{x} \]
\end{theorem}

\begin{example}
	Consider the function
	\[ h(x) = (x^2 + 1)^2 \]
	This is a simple application of chain rule, the two functions are
	\[ f(x) = x^2 \qquad g(x) = x^2 + 1 \]
	and so the derivative is 
	\[ h'(x) = 2(x^2 + 1)(2x) = 4x(x^2 + 1) \]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \sin(x^3) \]
	It's pretty obvious what the outer and inner functions are
	\[ h'(x) = \cos(x^3)(3x^2) = 3x^2 \cos(x^3) \]
	
	Now suppose we want the tangent line at $x_0 = \sqrt[3]{\pi}$. First note
	\[ h(x_0) = \sin(\pi) = 0 \qquad h'(x_0) = 3\sqrt[3]{\pi^2}\cos(\pi) = -3\sqrt[3]{\pi^2} \]
	Using point-slope form, the tangent line is
	\[ y - 0 = -3\sqrt[3]{\pi^2}(x - \sqrt[3]{\pi}) \]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \frac{1}{x^3 + 5} \]
	For fractions, it's easy to miss that this is actually a composition of two functions
	\[ f(x) = \frac{1}{x} = \inv x \qquad g(x) = x^3 + 5 \]
	and so the derivative is
	\[ h'(x) = -(x^3 + 5)^{-2}(3x^2) = -\frac{3x^2}{(x^3 + 5)^2}\]
\end{example}

\begin{example}
	Consider the function
	\[ h(x) = \cos(\cos(x^3)) \]
	This is an example of a nested chain rule, first we decompose
	\[ f(x) = \cos x \qquad g(x) = \cos(x^3) \]
	But now we have an issue, $g(x)$ is also a composition of functions
	\[ g(x) = j(k(x)) \qquad j(x) = \cos x \qquad k(x) = x^3 \]
	
	Starting from the top, recall that the chain rule state
	\[ h'(x) = f'(g(x)) g'(x) \]
	we can easily compute $f'(x)$, but we will need to use chain rule again to compute $g'(x)$
	\[ g'(x) = j'(k(x)) k'(x) = -\sin(x^3) (3x^2) = -3x^2 \sin(x^3) \]
	
	Putting the pieces together, we get
	\[ h'(x) = -\sin( \cos(x^3)) (-3x^2 \sin(x^3)) = 3x^2 \sin(x^3) \sin(\cos(x^3)) \]
\end{example}

A neat application of the chain rule is that it allows us to take derivatives of inverse functions. For a given function $f(x)$, the inverse, denoted $\inv f(x)$ is a function such that
\[ \inv f(f(x)) = f(\inv f(x)) = x \qquad \forall x \in \re \]

To clean up the notation, suppose $g(x) = \inv f(x)$, then we can use the chain rule to take derivatives of both sides
\begin{align*}
	\dv{x} x &= \dv{x} f(g(x)) \\
	1 &= f'(g(x)) g'(x) \\
	\therefore g'(x) &= \frac{1}{f'(g(x))} 
\end{align*}

\newpage 
If we recall that $g$ is simply the inverse of $f$, we get the following result:
\begin{theorem}[Inverse Rule]
	Let $f(x)$ be a function which is invertible and differentiable for all $x$, then
	\[ \dv{x} \inv f(x) = \frac{1}{f'(\inv f(x))} \]
	for all $x$ such that $f'(\inv f(x)) \neq 0$.
\end{theorem}

This is a powerful theorem because it lets us find the derivative of inverse functions without having to calculate them.

\begin{example}
	Take a simple example, suppose we want the derivative of the inverse of the following function
	\[ f(x) = \sqrt{x} \]
	We know how to take the derivative of this using power rule and the inverse is just $x^2$, so
	\[ \dv{x} \inv f(x) = \frac{1}{f'(\inv f(x))} = \qty(\frac{1}{2\sqrt{x^2}})^{-1} = 2x \]
	This is the same result as if we were to differentiate $x^2$ directly.
\end{example}

For an example where you can't simply just solve for the inverse, take the trigonometric functions.
\begin{example}
	Suppose we want to differentiate the inverse sin function
	\[ f(x) = \arcsin(x) \]
	We can't do much with this without using the inverse derivative rule, which let's us simply write
	\[ f'(x) = \frac{1}{\cos(\arcsin(x))} \]
	
	But where do we go from here? We have to remember that trig functions represent ratios between side lengths of a right triangle. For instance $\sin(x)$ is the ratio between opposite leg and hypotenuse of a right triangle with one angle measuring $x$ radians.
	
	When we say that an angle $\theta = \arcsin(x)$, we are saying that for a right triangle with one angle $\theta$ radians, the ratio of the opposite leg and hypotenuse is $x$. We can simplify this by assuming the hypotenuse is of length 1, for instance if we are in the unit circle.
	\begin{center}
		\includegraphics[scale=1]{images/Figure 3.3.1.png}
	\end{center}
	
	From this picture, we can see clearly that 
	\[ \cos(\theta) = \frac{\sqrt{1 - x^2}}{1} = \sqrt{1 - x^2} \]
	and thus the derivative in question is
	\[ f'(x) = \dv{x} \arcsin(x) = \frac{1}{\sqrt{1 - x^2}} \]
	
	There are two things to notice about this approach. First is our choice of hypotenuse, the fact that we chose it to be 1. This is easy to reconcile, if we chose any other value for the hypotenuse (for instance 2 or 0.5), then the opposite leg would scale accordingly ($2x$ and $0.5x$ respectively). Thus all the possible choices yield similar triangles, which means that $\cos(\theta)$ will be constant across all of them.
	
	The second, more interesting, choice was that the legs have positive length. For instance we could have drawn the triangle in the third quadrant and gotten a negative answer. This comes from how we define the inverse trig functions (WARNING: higher level math ahead):
	
	An important fact to note about sine (and other trig functions) is that they are period and an unfortunate consequence of this is that they are neither injective (one-to-one) nor surjective (onto). Failing to be injective means that for a given $y$ value, we cannot associate just one $x$ value (\emph{the} inverse) because that are infinitely many such $x$'s. Failing to be surjective means that they are $y$ values which do not have an inverse altogether (for instance $\arcsin(2)$ is undefined because $-1 \leq \sin(x) \leq 1$).
	
	In mathematics, we say that the trig functions do a form a bijection from the real numbers to the real numbers. Unfortunately for us, only bijective functions have well defined inverses, so what can we do? Well we can restrict the domain of the inverse to force the function to be bijective. In the case of $\sin(x)$, we take a cut of the function from $-\pi/2$ to $\pi/2$, giving us one full ``branch" which we can invert.
	
	This forces $\theta$ to lie in quadrants 1 or 4, meaning that $\cos(\theta)$ will always be positive. This solves the main issue at hand, the other (less important in this context) issue is rectified by only defining $\arcsin(x)$ for $-1 \leq x \leq 1$.
\end{example}

\newpage 
\begin{example}
	The long argument from above is more immediately important for the next example, suppose we have
	\[ f(x) = \arcsec(x) \]
	Going through the same motions as before, we get
	\[ f'(x) = \frac{\cos^2(\arcsec(x))}{\sin(\arcsec(x))} = \frac{x}{x^2\sqrt{x^2 - 1}} \]
	We may be tempted to cancel out the $x$'s right away, but that is actually incorrect. We have to do the same thing, taking a cut of $\sec(x)$ between 0 and $\pi$ to get one complete ``branch" to invert. For these values of $x$, we will get that $\sin(x) \geq 0$ which forces $f'(x) \geq 0$. Thus when we cancel, we must insert an absolute value to get the correct derivative:
	\[ f'(x) = \frac{1}{|x|\sqrt{x^2 - 1}}\]
\end{example}

The remaining inverse trig derivatives are left as an exercise to the reader, but I will list them here for convenience.

\begin{proposition}[Derivatives of Inverse Trig Functions]
	\begin{align*}
		\dv{x} \arcsin(x) = \dv{x} \inv\sin(x) &= \frac{1}{\sqrt{1 - x^2}} \\
		\dv{x} \arccos(x) = \dv{x} \inv\cos(x) &= -\frac{1}{\sqrt{1 - x^2}} \\
		\dv{x} \arctan(x) = \dv{x} \inv\tan(x) &= \frac{1}{1 + x^2} \\
		\dv{x} \arccsc(x) = \dv{x} \inv\csc(x) &= -\frac{1}{|x|\sqrt{x^2 - 1}} \\
		\dv{x} \arcsec(x) = \dv{x} \inv\sec(x) &= \frac{1}{|x|\sqrt{x^2 - 1}} \\
		\dv{x} \arccot(x) = \dv{x} \inv\cot(x) &= -\frac{1}{1 + x^2} 
	\end{align*}
\end{proposition}

\newpage 
\subsection{Derivatives of Special Functions}
In this section we give the derivatives of functions not covered by the power rule, for instance trigonometric functions and exponential functions. We will start with the trig functions.

We compute the derivative of sine directly from the limit definition using sum to product identities
\begin{align*}
	\dv{x} (\sin x) &= \lim_{h \to 0} \frac{\sin(x + h) - \sin(x)}{h} \\
	&= \lim_{h \to 0} \frac{2\sin(h/2)\cos(x + h/2)}{h} \\
	&= \lim_{h \to 0} \frac{\sin(h/2)}{h/2} \cdot \lim_{h \to 0} \cos(x + h/2) \\
	&= 1 \cdot \lim_{h \to 0} \cos(x + h/2) \\
	&= \cos(x) \\
	\dv{x} (\cos x) &= \lim_{h \to 0} \frac{\cos(x + h) - \cos(x)}{h} \\
	&= \lim_{h \to 0} \frac{-2\sin(h/2)\sin(x + h/2)}{h} \\
	&= \lim_{h \to 0} \frac{\sin(h/2)}{h/2} \cdot \lim_{h \to 0} -\sin(x + h/2) \\
	&= 1 \cdot \lim_{h \to 0} -\sin(x + h/2) \\
	&= -\sin(x) 
\end{align*}

The derivative of tangent comes from quotient rule
\begin{align*}
	\dv{x} (\tan x) &= \dv{x} \qty(\frac{\sin x}{\cos x}) \\
	&= \frac{(\cos x)(\cos x) - (\sin x)(-\sin x)}{\cos^2 x} \\
	&= \frac{\cos^2 x + \sin^2 x}{\cos^2 x} \\
	&= \frac{1}{\cos^2 x} = \sec^2 x 
\end{align*}

Now that we can take derivatives of trig functions, we have a more useful use case of the product rule.
\begin{example}
	Consider the function
	\[ f(x) = x^2 \sin x \]
	This product cannot simply be expanded, we are forced to use product rule
	\[ f'(x) = 2x \sin x + x^2 \cos x \]
\end{example}

Using quotient rule, we can take derivatives of the remaining trig functions. I'll list them here for your convenience:
\begin{proposition}[Trig Derivatives]
	\begin{align*}
		\dv{x} (\sin x) &= \cos x \\
		\dv{x} (\cos x) &= -\sin x \\
		\dv{x} (\tan x) &= \frac{1}{\cos^2 x} = \sec^2 x \\
		\dv{x} (\csc x) &= - \frac{\cos x}{\sin^2 x} = -\csc x \cot x \\
		\dv{x} (\sec x) &= \frac{\sin x}{\cos^2 x} = \sec x \tan x \\
		\dv{x} (\cot x) &= -\frac{1}{\sin^2 x} = -\csc^2 x \\
	\end{align*}
\end{proposition}

Note that because sine and cosine are related by derivatives, we have the chain
\[ \sin x \thus \cos x \thus -\sin x \thus -\cos x \thus \sin x \thus \cdots \]
This is our first example of a function which is both infinitely differentiable and has nontrivial higher order derivatives. Compare this to polynomials, which always end up going to 0 if you take enough derivatives.

\begin{example}
	Suppose we want to know the equation of the tangent line of the function
	\[ f(x) = \sin x \cos x \]
	at the point $x = \pi$. First note that the derivative is
	\[ f'(x) = (\cos x)(\cos x) + (\sin x)(-\sin x) = \cos^2 x - \sin^2 x = \cos(2x) \]
	Recall that the derivative gives us the slope of the tangent line, it is $f'(\pi) = 1$. Now all we need is a point. The tangent line touches the function at only one point, that point must be the value of the function at $x = \pi$, which is $f(\pi) = 0$. The easiest way to find the equation is to use point slope form and convert if necessary
	\[ y - 0 = 1 \cdot (x - \pi) \thus y = x - \pi \]
\end{example}

\begin{example}
	A particle undergoing simple harmonic motion (for instance a mass on an ideal spring) has equation
	\[ x(t) = 5 \cos(t) \]
	We can use this to find the velocity at any time $t$
	\[ v(t) = x'(t) = -5 \sin(t) \]
	The velocity function is also periodic, by looking more closely we see that 
	\[ v(t) = 0 \iff t = 0, \pi, 2\pi, 3\pi, \cdots \]
	This is also when the spring is furthest away from the center (at $\pm 5$). The mass actually has zero speed when it reaches it's furthest point and this happens infinitely many times.
\end{example}

Finally, we have the exponential and logarithmic functions. The exponential is very easy to remember

\begin{theorem}[Exponential Derivative]
	\[ \dv{x} e^x = e^x \]
\end{theorem}

It's slightly subtle, but this actually let's us take derivative of all exponential functions, not just the natural one. We do this by converting into the natural exponential and then using chain rule:
\[ \dv{x} a^x = \dv{x} e^{x \ln a} =  e^{x \ln a} \ln a = a^x \ln a \]

This holds for any constant $a$, for instance the derivative of $2^x$ is $2^x \ln 2$.

\begin{example}
	Consider the function
	\[ f(x) = x e^{2x} \]
	The first derivative is
	\[ f'(x) = e^{2x} + 2x e^{2x} \]
	The second derivative is 
	\[ f''(x) = 2 e^{2x} + 2e^{2x} + 2x (2e^{2x}) = 4 e^{2x} + 4x e^{2x} \]
\end{example}

The logarithmic function is a bit more annoying deal with.

\begin{theorem}[Logarithmic Derivative]
	\[ \dv{x} \ln x = \frac{1}{x} \]
\end{theorem}

Just like the exponential, we can extend this to other logarithms by using the change of base formula.
\[ \dv{x} \log_a x = \dv{x} \frac{\ln x}{\ln a} = \frac{1}{x \ln a} \]

\begin{example}
	Consider the function
	\[ f(x) = ln(x^3 + 2x + 4) \]
	The derivative is
	\[ f'(x) = \frac{3x^2 + x}{x^3 + 2x + 4} \]
\end{example}

Logarithms have some nice properties that sometimes makes the derivative easier.

\begin{example}
	Consider the function
	\[ f(x) = \ln(\frac{x}{x^2 \sin x}) \]
	We could try to use chain rule directly, but then we would have to deal with the nasty quotient inside. Instead we can first simplify
	\[ f(x) = \ln x - \ln x^2 - \ln \sin x \]
	and now we can differentiate
	\[ f'(x) = \frac{1}{x} - \frac{2x}{x^2} - \frac{\cos x}{\sin x} \]
\end{example}

\newpage 
\subsection{Implicit Differentiation}
Implicit differentiation is a bit of a strange technique. It's similar to taking derivatives of inverses, but not really. The problem is that some functions cannot be written in the form $y = \cdots$, for instance the equation of the unit circle is $x^2 + y^2 = 1$. To be able to find tangent lines, we use implicit differentiation. 

The main trick behind implicit differentiation is the fact that the derivative of $y$ is $y'$. That's it. Let's see how this trick gets used in an example.

\begin{example}
	Returning to the circle example, consider a circle centered on the origin with radius 2
	\[ x^2 + y^2 = 4 \]
	Suppose we want to know the derivative at the point $(0, 2)$. We can take the derivative of both sides, clearly the right side is just 0. The derivative of $x^2$ is just $2x$ using power rule, but the $y^2$ is tricky. 
	
	We have the recognize that $y$ is not just a variable, it is a function. So when we take derivative we must use the appropriate rule(s), in this case chain rule.
	\[ \dv{x} y^2 = 2y \dv{x} y = 2y y' \]
	Going back to the original function, we have
	\[ 2x + 2y y' = 0 \thus y' = -\frac{x}{y} \]
	
	Note that the derivative is no longer just a function of $x$, it is a function of both. If you want to know the derivative at some point, you need both the $x$ and $y$ values of that point. So at the point $(0, 2)$, the derivative is
	\[ y' = -\frac{0}{2} = 0 \]
	If we wanted the tangent line at the point, we have
	\[ y - 2 = 0(x - 0) \thus y = 2 \]
	which is just a horizontal line on top of the circle.
\end{example}

\begin{example}
	For an example with a few more rules involved, consider
	\[ x \sin(y) + x^3 = y \]
	The first term will require both product and chain rule to properly differentiate, let's examine that term by itself
	\[ \dv{x} x \sin(y) = \sin(y) + x \dv{x} \sin(y) = \sin(y) + x \cos(y) \dv{x} y = \sin(y) + xy'\cos(y) \]
	The remaining terms are easy and we get
	\[ \sin(y) + xy'\cos(y) + 3x^2 = y' \thus y' = \frac{\sin(y) + 3x^2}{1 - x\cos(y)} \]
\end{example}

\begin{example}
	Here's an example with a triple product rule
	\[ xy \cos(y) = x \]
	The right hand side obviously becomes 1, the left hand side goes like this
	\begin{align*}
		\dv{x} xy\cos(y) &= y \cos(y) + x \dv{x} y\cos(y) \\
		&= y \cos(y) + x \qty( y'\cos(y) + y \dv{x} \cos(y) ) \\
		&= y \cos(y) + x (y'\cos(y) - y y' \sin(y)) \\
		&= y' (x \cos(y) - y\sin(y)) + y\cos(y)
	\end{align*}
	and the final derivative becomes
	\[ y' = \frac{1 - y\cos(y)}{x \cos(y) - y \sin(y)} \]
\end{example}

We can also take higher order derivatives by simply differentiating implicitly again.

\begin{example}	
	Consider the function
	\[ y = x \sin(y) \]
	Implicitly differentiating once gives
	\[ y' = \sin(y) + xy' \cos(y) \thus y' = \frac{\sin(y)}{1 - x \cos(y)}\]
	We could solve for $y'$ and differentiate again, but that would introduce a nasty quotient and we would need to combine quotient, product, and chain rule to get the second derivative. Instead we'll leave it as is and use implicit differentiation again:
	\[ y'' = y' \sin(y) + y' \cos(y) + x y'' \cos(y) + x (y')^2 \cos(y) \]
	and the second derivative is
	\[ y'' = \frac{y'\sin(y) + y'\cos(y) + x(y')^2 \cos(y)}{1 - x \cos(y)} \]
	
	You may object that I left my $y'$s out, but this was is actually cleaner and more understandable. If we want to compute the second derivative at a value, say $(3, 0)$. We first compute the first derivative
	\[ y' = \frac{\sin(0)}{1 - 3\cos(0)} = 0 \]
	Then use that to compute the second derivative
	\[ y'' = \frac{0}{1 - 3 \cos(0)} = 0 \]
	If you \emph{really} hate having $y'$s out in the open, you may substitute the expression we found earlier for $y'$, but be warned that the result usually isn't pretty. 
\end{example}

Implicit differentiation let's us leverage logarithms to simplify certain derivatives. By taking the natural logarithm of both sides before differentiating, we can sometimes simplify the problem.

\begin{example}
	Consider the function
	\[ y = \frac{x \sqrt{\sin x}}{e^x \tan^3 x} \]
	First we take the logarithm
	\begin{align*}
		\ln y &= \ln x + \ln \sqrt{\sin x} - \ln e^x - \ln \tan^3 x \\
		&= \ln x + \frac{1}{2} \ln \sin x - x - 3 \ln \tan x
	\end{align*}
	and now we can differentiate
	\[ \frac{y'}{y} = \frac{1}{x} + \frac{\cos x}{2 \sin x} - 1 - \frac{3 \sec^2 x}{\tan x} \]
	If we wish to solve for $y'$, we use the original expression
	\[ y' = \qty( \frac{1}{x} + \frac{\cos x}{2 \sin x} - 1 - \frac{3}{\sin x \cos x} ) \frac{x \sqrt{\sin x}}{e^x \tan^3 x} =  \qty( \frac{1}{x} + \frac{\cos x}{2 \sin x} - 1 - \frac{6}{\sin 2x} ) \frac{x \sqrt{\sin x}}{e^x \tan^3 x} \]
\end{example}